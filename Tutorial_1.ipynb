{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar6zEZFgEGVK"
      },
      "source": [
        "# Task : Amazon Reviews Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
            "Requirement already satisfied: whoosh in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.4)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.1.post1)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usmim\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: click in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usmim\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\usmim\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\usmim\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas nltk whoosh scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuvVNP_nEGVD",
        "outputId": "cf9d02b6-46eb-449e-8d65-2f17a6fb06d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\usmim\\AppData\\Local\\Temp\\ipykernel_9988\\2631108614.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NLTK stopwords and wordnet (lexical database of English)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\usmim\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\usmim\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v31-MGXIEGVM"
      },
      "source": [
        "## Using Pandas for reading data and displaying the last five rows in the dataframe(i.e. table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reading the dataset using pandas and displaying the table(i.e dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m4A7BsCxEGVN",
        "outputId": "42352d1c-0f1a-4ad6-8073-855eae40ed40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45594</th>\n",
              "      <td>Mary Mora</td>\n",
              "      <td>Amazon Smile donates. Make sure you get all se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45595</th>\n",
              "      <td>Marie Elliott</td>\n",
              "      <td>After having problems with the app and having ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45596</th>\n",
              "      <td>Dan Preston</td>\n",
              "      <td>Used to be great. Got greedy, they ruined the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45597</th>\n",
              "      <td>Jhosh</td>\n",
              "      <td>New search bar location sucks. At least give m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45598</th>\n",
              "      <td>Christopher Read</td>\n",
              "      <td>for me personally I use Amazon prime due to be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               userName                                            content\n",
              "45594         Mary Mora  Amazon Smile donates. Make sure you get all se...\n",
              "45595     Marie Elliott  After having problems with the app and having ...\n",
              "45596       Dan Preston  Used to be great. Got greedy, they ruined the ...\n",
              "45597             Jhosh  New search bar location sucks. At least give m...\n",
              "45598  Christopher Read  for me personally I use Amazon prime due to be..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('amazon_reviews.csv')\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>David Lane (littleBIG)</td>\n",
              "      <td>it's very functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Emery Hayward</td>\n",
              "      <td>Trash app login function now long works.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sohaila Elzayady</td>\n",
              "      <td>One of my favorite apps ðŸ¥°</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mo jo</td>\n",
              "      <td>Lost my former purchases and my wish list this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Simba Davies</td>\n",
              "      <td>Brilliant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 userName                                            content\n",
              "0  David Lane (littleBIG)                               it's very functional\n",
              "1           Emery Hayward           Trash app login function now long works.\n",
              "2        Sohaila Elzayady                          One of my favorite apps ðŸ¥°\n",
              "3                   mo jo  Lost my former purchases and my wish list this...\n",
              "4            Simba Davies                                          Brilliant"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displaying information about the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_48fdscuEGVP",
        "outputId": "eb0db1f2-e2c3-4fd7-dc61-5ededd7a6d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45599 entries, 0 to 45598\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   userName  45599 non-null  object\n",
            " 1   content   45599 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 712.6+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Some example pandas operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        David Lane (littleBIG)\n",
              "1                 Emery Hayward\n",
              "2              Sohaila Elzayady\n",
              "3                         mo jo\n",
              "4                  Simba Davies\n",
              "                  ...          \n",
              "45594                 Mary Mora\n",
              "45595             Marie Elliott\n",
              "45596               Dan Preston\n",
              "45597                     Jhosh\n",
              "45598          Christopher Read\n",
              "Name: userName, Length: 45599, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['userName']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                     it's very functional\n",
              "1                 Trash app login function now long works.\n",
              "2                                One of my favorite apps ðŸ¥°\n",
              "3        Lost my former purchases and my wish list this...\n",
              "4                                                Brilliant\n",
              "                               ...                        \n",
              "45594    Amazon Smile donates. Make sure you get all se...\n",
              "45595    After having problems with the app and having ...\n",
              "45596    Used to be great. Got greedy, they ruined the ...\n",
              "45597    New search bar location sucks. At least give m...\n",
              "45598    for me personally I use Amazon prime due to be...\n",
              "Name: content, Length: 45599, dtype: object"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# viewing a column in the dataset\n",
        "data['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "userName                                                mo jo\n",
              "content     Lost my former purchases and my wish list this...\n",
              "Name: 3, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# viewing a row in the dataset\n",
        "data.iloc[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"it's very functional\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# viewing a cell in the dataset\n",
        "data['content'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW15bZJrEGVQ"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert to lowercase and removing special characters and keeping text only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stopwords_removal(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentence = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performing lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sentence = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Applying on our review data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                               functional\n",
            "1                       trash app login function long work\n",
            "2                                        one favorite apps\n",
            "3        lost former purchase wish list wa disappointin...\n",
            "4                                                brilliant\n",
            "                               ...                        \n",
            "45594    amazon smile donates make sure get set learn w...\n",
            "45595                   problem app reinstall working fine\n",
            "45596    used great got greedy ruined music app longer ...\n",
            "45597    new search bar location suck least give option...\n",
            "45598    personally use amazon prime due disabled deliv...\n",
            "Name: content, Length: 45599, dtype: object\n"
          ]
        }
      ],
      "source": [
        "data['content'] = data['content'].apply(clean_text)\n",
        "data['content'] = data['content'].apply(lemmatize)\n",
        "data['content'] = data['content'].apply(stopwords_removal)\n",
        "\n",
        "print(data['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "functional\n"
          ]
        }
      ],
      "source": [
        "# iterating over the rows of a specific column in the dataset\n",
        "for d in data['content']:\n",
        "    print(d)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "David Lane (littleBIG)\n",
            "functional\n"
          ]
        }
      ],
      "source": [
        "# iterating over the rows of the dataset\n",
        "for index, row in data.iterrows():\n",
        "    print(row['userName'])\n",
        "    print(row['content'])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhjfKqBEGVU"
      },
      "source": [
        "## Term-Document Incidence Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def term_document_incidence_matrix(data):\n",
        "    # initialize an empty set to store unique words\n",
        "    words = set()\n",
        "    \n",
        "    # iterate over the content column in the dataframe and update the set with unique words\n",
        "    for content in data:\n",
        "        words.update(content.split())\n",
        "    \n",
        "    # convert the set to a list and sort it\n",
        "    words = list(words)\n",
        "    words.sort()\n",
        "    \n",
        "    # define an empty list to store the matrix\n",
        "    matrix = []\n",
        "    \n",
        "    # create a row for each content in the dataframe \n",
        "    for content in data:\n",
        "        \n",
        "        # store the row as a list of zeros with the length of the unique words\n",
        "        row = [0] * len(words)\n",
        "        \n",
        "        # for each word in the content, update the row with 1 where the word is found\n",
        "        for word in content.split():\n",
        "            row[words.index(word)] = 1\n",
        "        \n",
        "        matrix.append(row)\n",
        "    \n",
        "    # return the matrix as a dataframe with the words as columns\n",
        "    return pd.DataFrame(matrix, columns=words).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "G9Ll4phLEGVV",
        "outputId": "adf721d4-dfac-47a2-953e-4857018bc3fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aamazon</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aarives</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ability</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abismal</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>able</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zero</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zfold</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipper</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zon</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zoom</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087 rows Ã— 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0     1     2     3     4     5     6     7     8     9     ...  \\\n",
              "aamazon     0     0     0     0     0     0     0     0     0     0  ...   \n",
              "aarives     0     0     0     0     0     0     0     0     0     0  ...   \n",
              "ability     0     0     0     0     0     0     0     0     0     0  ...   \n",
              "abismal     0     0     0     0     0     0     0     0     0     0  ...   \n",
              "able        0     0     0     0     0     0     0     0     0     0  ...   \n",
              "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
              "zero        0     0     0     0     0     0     0     0     0     0  ...   \n",
              "zfold       0     0     0     0     0     0     0     0     0     0  ...   \n",
              "zipper      0     0     0     0     0     0     0     0     0     0  ...   \n",
              "zon         0     0     0     0     0     0     0     0     0     0  ...   \n",
              "zoom        0     0     0     0     0     0     0     0     0     0  ...   \n",
              "\n",
              "         1990  1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
              "aamazon     0     0     0     0     0     0     0     0     0     0  \n",
              "aarives     0     0     0     0     0     0     0     0     0     0  \n",
              "ability     0     0     0     0     0     0     0     0     0     0  \n",
              "abismal     0     0     0     0     0     0     0     0     0     0  \n",
              "able        0     0     0     0     0     0     0     0     0     0  \n",
              "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "zero        0     0     0     0     0     0     0     0     0     0  \n",
              "zfold       0     0     0     0     0     0     0     0     0     0  \n",
              "zipper      0     0     0     0     0     0     0     0     0     0  \n",
              "zon         0     0     0     0     0     0     0     0     0     0  \n",
              "zoom        0     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[5087 rows x 2000 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix = term_document_incidence_matrix(data['content'][:2000])\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5087, 2000)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "1995    0\n",
              "1996    0\n",
              "1997    0\n",
              "1998    0\n",
              "1999    0\n",
              "Name: good, Length: 2000, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.loc['good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.loc['good'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7       1\n",
              "16      1\n",
              "26      1\n",
              "31      1\n",
              "37      1\n",
              "       ..\n",
              "1828    1\n",
              "1838    1\n",
              "1900    1\n",
              "1925    1\n",
              "1935    1\n",
              "Name: good, Length: 168, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_matrix = matrix.loc['good']\n",
        "filtered_matrix = filtered_matrix[(filtered_matrix > 0)]\n",
        "filtered_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Boolean Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def boolean_search(data, matrix, search_terms, operator='AND'):\n",
        "    try:\n",
        "        # Ensure that the search terms are in lowercase\n",
        "        search_terms = [term.lower() for term in search_terms]\n",
        "                \n",
        "        # Filter the matrix to include only the search terms\n",
        "        filtered_matrix = matrix.loc[search_terms]\n",
        "    \n",
        "        # Find all reviews where all terms appear (boolean AND operation)\n",
        "        if operator == 'AND':\n",
        "            valid_indices = filtered_matrix.columns[(filtered_matrix > 0).all()]\n",
        "            \n",
        "        # Find all reviews where any term appears (boolean OR operation)\n",
        "        elif operator == 'OR':\n",
        "            valid_indices = filtered_matrix.columns[(filtered_matrix > 0).any()]\n",
        "            \n",
        "        else:\n",
        "            raise ValueError(\"Operator must be 'AND' or 'OR'\")\n",
        "\n",
        "        # Select and return the relevant data using the valid indices\n",
        "        return data.loc[valid_indices, ['userName', 'content']]\n",
        "\n",
        "    except KeyError as e:\n",
        "\n",
        "        # Handle the case where one or more search terms are not in the matrix\n",
        "        print(f\"Warning: {str(e).strip('[]')} not found\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if any term is not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         userName                                            content\n",
            "694  Charlie Cook  happy amazon shopping experience cost wide ran...\n"
          ]
        }
      ],
      "source": [
        "result = boolean_search(data, matrix, ['good', 'product','delivery'], operator='AND')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inverted Index using Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[1]\n",
            "{'a': [1], 'b': [4]}\n",
            "{'a': [1, 5], 'b': [4]}\n"
          ]
        }
      ],
      "source": [
        "# an example dictionary\n",
        "d = {}\n",
        "\n",
        "d['a'] = [1]\n",
        "\n",
        "print(d['a'])\n",
        "print(d.get('a'))\n",
        "\n",
        "d['b'] = [4]\n",
        "print(d)\n",
        "\n",
        "\n",
        "d['a'].append(5)\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_inverted_index(data):\n",
        "    inverted_index = {}\n",
        "    \n",
        "    # iterating over the rows of the dataframe\n",
        "    # here i is the index of the row and row is the content of the row\n",
        "    for i, row in data.iterrows():\n",
        "        \n",
        "        # tokenize the content into words\n",
        "        words = row['content'].split()\n",
        "        \n",
        "        # iterate over the words and update the inverted index\n",
        "        for word in words:\n",
        "            \n",
        "            # find the word in the inverted index\n",
        "            if word in inverted_index:    \n",
        "                # add the id of the document to the word\n",
        "                inverted_index[word].add(i)\n",
        "            else:\n",
        "                # else create a new entry for the word\n",
        "                inverted_index[word] = {i}\n",
        "    # return the inverted index dictionary\n",
        "    return inverted_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inverted_index_search(data, inverted_index, search_terms):\n",
        "    \n",
        "    try:\n",
        "        \n",
        "        # if a term is in the search terms and in the inverted index then get the set of indices\n",
        "        sets_of_indices = [set(inverted_index[term]) for term in search_terms if term in inverted_index]\n",
        "        # print(sets_of_indices)\n",
        "        \n",
        "        # check if there are no sets of indices then return an empty dataframe\n",
        "        if not sets_of_indices:\n",
        "            return pd.DataFrame() \n",
        "\n",
        "        #  find the intersection of the sets of indices of the search terms\n",
        "        #  the documents that are present in all the sets are the relevant documents\n",
        "        # this is the boolean AND operation\n",
        "        valid_indices = set.intersection(*sets_of_indices)\n",
        "    \n",
        "\n",
        "        # Convert the set of valid indices to a list\n",
        "        valid_indices_list = list(valid_indices)\n",
        "\n",
        "        # return the dataframe with the rows of the valid indices of our search terms\n",
        "        return data.loc[valid_indices_list, ['userName', 'content']]\n",
        "   \n",
        "    except KeyError as e:\n",
        "        # Handle the case where one or more search terms are not in the matrix\n",
        "        print(f\"Warning: {str(e).strip('[]')} not found\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                userName  \\\n",
            "8774                 Ladislav Jurdik ml.   \n",
            "1993                Susanna Monika Faltz   \n",
            "3212                        2023 Warzone   \n",
            "6163                            Matej S.   \n",
            "2391                 Michail Savvoulidis   \n",
            "3673                       A Google user   \n",
            "9313                             Mandy O   \n",
            "9701                           J Gilbert   \n",
            "619                        Cortes Cortes   \n",
            "7595                           natasa vl   \n",
            "3951  Dimitrios Troumpetakis - Voutsinos   \n",
            "1843                         Leonardo MT   \n",
            "9462                       Shirley Drury   \n",
            "7416                    Theodore Tekkers   \n",
            "187                      David Gutierrez   \n",
            "8510                   Deb & Mark Draper   \n",
            "\n",
            "                                                content  \n",
            "8774  worst amazon de experience ever lost trust ord...  \n",
            "1993  fix app language setting completely missing ap...  \n",
            "3212  need update gps tracking item location like di...  \n",
            "6163  app need improvement unable copy text within a...  \n",
            "2391  amazon de deletes negative review item care ri...  \n",
            "3673  usable start app first get asked choose right ...  \n",
            "9313  update updated app even worse cannot checkout ...  \n",
            "9701  slow clunky also often receive de skoenetracki...  \n",
            "619   shop local ever since covid amazon ha gone com...  \n",
            "7595  amazon de could give minus would first time li...  \n",
            "3951  happy support ad search engine doe meant gener...  \n",
            "1843  upset amazon since last year app show next mes...  \n",
            "9462  great stuff choose amazon prime allows next da...  \n",
            "7416  good app buy thing like return return policy b...  \n",
            "187   algo se tiene que cambiar e posible esperar to...  \n",
            "8510  latest update working click product everything...  \n",
            "\n",
            " Returned 16 documents\n"
          ]
        }
      ],
      "source": [
        "# call the function to create inverted index\n",
        "inverted_index = create_inverted_index(data[:10000])\n",
        "# print(inverted_index)\n",
        "\n",
        "\n",
        "# search using inverted index\n",
        "result = inverted_index_search(data, inverted_index, ['de'])\n",
        "print(result)\n",
        "print(f'\\n Returned {len(result)} documents')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latency Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 0.008294820785522461 seconds ---\n",
            "--- 0.00860595703125 seconds ---\n",
            "--- 0.006006002426147461 seconds ---\n",
            "\n",
            "the average latency 0.007964372634887695\n"
          ]
        }
      ],
      "source": [
        "# average latency calculation for boolean search for 3 queries\n",
        "import time\n",
        "\n",
        "latency = []\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "boolean_search(data, matrix, ['good', 'product','delivery'], operator='AND')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "latency.append(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "boolean_search(data, matrix, ['good', 'product','delivery'], operator='AND')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "latency.append(time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "boolean_search(data, matrix, ['good', 'product','delivery'], operator='AND')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "latency.append(time.time() - start_time)\n",
        "\n",
        "# average latency of the times\n",
        "latency = sum(latency)/len(latency)\n",
        "print(\"\\nthe average latency: \",latency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Whoosh Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# simple search using whoosh\n",
        "from whoosh import index\n",
        "from whoosh.fields import Schema, TEXT, ID\n",
        "from whoosh.analysis import StemmingAnalyzer\n",
        "from whoosh.qparser import QueryParser\n",
        "from whoosh.index import create_in\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define a schema \n",
        "schema = Schema(\n",
        "    userName=TEXT(stored=True),\n",
        "    content=TEXT(analyzer=StemmingAnalyzer(), stored=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make a directory to store the index\n",
        "if not os.path.exists(\"indexdir\"):\n",
        "    os.mkdir(\"indexdir\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the index schema and create an index\n",
        "ix = create_in(\"indexdir\", schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_to_index(data):\n",
        "    # create a writer object\n",
        "    writer = ix.writer()\n",
        "    # write the data to the index\n",
        "    for i, row in data.iterrows():\n",
        "        writer.add_document(userName=row['userName'], content=row['content'])\n",
        "    # commit the writer\n",
        "    writer.commit()\n",
        "\n",
        "# call the function to write to the index\n",
        "write_to_index(data[:10000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  search using whoosh\n",
        "def whoosh_search(searcher, query):\n",
        "    \n",
        "    # create a query parser for the content field in the index schema\n",
        "    query_parser = QueryParser(\"content\", ix.schema)\n",
        "    \n",
        "    # parse the query string\n",
        "    query = query_parser.parse(query)\n",
        "    \n",
        "    # search the index\n",
        "    results = searcher.search(query)\n",
        "    # return the results\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Top 10 Results for And([Term('content', 'good'), Term('content', 'deliveri'), Term('content', 'product')]) runtime=0.044635600002948195>\n"
          ]
        }
      ],
      "source": [
        "# create a searcher object not function\n",
        "searcher = ix.searcher()\n",
        "\n",
        "# whoosh search for the query using the searcher object\n",
        "result = whoosh_search(searcher, 'good delivery product')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Hit {'content': 'good product good price fast delivery', 'userName': 'John Williams'}>\n",
            "<Hit {'content': 'amazon shopping ha extreme product ordered excellent delivery good', 'userName': 'melanie hastings'}>\n",
            "<Hit {'content': 'good product time delivery could bit done timely manner', 'userName': 'Randall Liestman'}>\n",
            "<Hit {'content': 'review improved many fraudulent lot wrong product always start star review go delivery good bad blame goin ups want return delivery container hope remember customer service good absolute worst part shopping amazon promotes product search product throw unrelated product get interest purchase go ebay trouble finding product', 'userName': 'Dave Orozco'}>\n",
            "<Hit {'content': 'always good product wise chosen delivery people really suck seems cannot read basic straight forward delivery instruction mean basic', 'userName': 'William Marshall'}>\n",
            "<Hit {'content': 'happy amazon shopping experience cost wide range availability product good alternative also shown searching useful delivery time alternative delivery option locker also good shame unable manage delivery driver often huge let packaging good well return refund managed simple prompt way customer service usually resolve matter well', 'userName': 'Charlie Cook'}>\n",
            "<Hit {'content': 'good app time charging huge delivery charge compared flipkart use avoid delivery charge ordered many thing search one item amazon delivery charge wa choose product quantity delivery charge doubled choose quantity avoid delivery charge thus give star', 'userName': 'shibu m'}>\n",
            "<Hit {'content': 'bad delivery driver actualy deliver parcel time call customer service parcel product good edit canceled prime membership see point even doe say next day delivery day delivery end say receive parcel day', 'userName': 'Elena-Bogdana Darca'}>\n",
            "<Hit {'content': 'one biggest company earth think app would flawless delivery time given shopping change purchase product depending address even though already ha address shopping click enlarge product image always buffering time load regardless good service wi fi', 'userName': 'Nathan Shortt'}>\n",
            "<Hit {'content': 'generally good pesters constantly buy poor value prime product thereby making app difficult use often lie delivery locker full want notification progress order also pesters advert deal interest', 'userName': 'User name name'}>\n"
          ]
        }
      ],
      "source": [
        "for res in result:\n",
        "    print(res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
